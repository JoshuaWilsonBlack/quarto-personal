{
  "hash": "273210aa65f53ac668403e5f6f3b0361",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Model Check and Significance Testing for Vowel Space GAMMs\nauthor: Joshua Wilson Black\ndate: '2022-08-30'\nslug: significance-testing-for-vowel-space-gamms\ncategories: \n  - GAMMs\n  - vowels\n  - sociolinguistics\ndescription: 'Checking GAMM models, significance tests, and visualisation for by-vowel models.'\nimage: feature.jpg\n---\n\n\n## Introduction\n\nIn a [previous post](https://joshua.wilsonblack.nz/post/visualising-vowel-space-gamms/), \nI set out a workflow for fitting and visualising generalised\nadditive mixed models for F1 and F2 of a series of vowels and using these to\nvisualise change over an entire vowel space.\n\nIn that post, I waved off the issue of evaluating individual models. In this \npost I'd like to fill out two aspects of this and link them to the workflow\nI presented in the previous post. The first is the use of the `gam.check`\nfunction to work out if your smooths enable sufficient 'wiggliness' for your\ndata and whether the assumption of normally distributed residuals holds. The\nsecond is to show how information about model significance can be extracted both\nin terms of significance of change in a given vowels trajectory _over time_ and\nin terms of the difference _between_ the trajectories of, say, men and women \n(following the recent advice of \n[Márton Sóskuthy](https://www.sciencedirect.com/science/article/pii/S009544702030108X).\n\nWe'll very quickly run through fitting models using the nest and mutate\napproach (using `purrr`), look at the use of `gam.check` within this framework,\nand then turn to significance testing. I'll conclude by adding an indication\nof significance to the static and animated vowel space plots presented in the\nprevious post.\n\n![NZBC Presents Logo ([source](https://www.lonely.geek.nz/kiwi-tv/index.php/tv-shows-mainmenu-42/42-help-needed/2291-nzbc-presents-nh))](feature.jpg)\n\n## Model Fit (Again)\n\nI'll rush over this part, given that it is covered in the previous post. \n\nThree things are worth noting:\n\n1. I'm bringing in the data for the models using my own package `nzilbb.vowels`.\nThis is _very much_ work in progress and I don't promise anything about it's \nfuture versions! I will endeavour to keep this post functional.\n\n2. I'll point out where the structure differs from that used in the previous \npost.\n\n3. Unlike the previous post, I'm using raw token data from each speaker rather\nthan just taking their mean values. This makes the data a little noisier and\nthe models a little harder to fit.\n\nLet's load some libraries:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Required tidyverse packages \n# (I occasionally try to do without 'library(tidyverse)')\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(purrr)\nlibrary(glue)\nlibrary(ggplot2)\nlibrary(gganimate)\n\n# gtools library for generating pval stars.\nlibrary(gtools)\n\n# mgcv for gamms, itsadug for gamm visualisation\nlibrary(mgcv)\nlibrary(itsadug)\n\n# nzilbb.vowels for data and some helper functions\n# To install, use remotes::install_github('JoshuaWilsonBlack/nzilbb_vowels')\nlibrary(nzilbb.vowels)\n```\n:::\n\n\nOur data is built in to `nzilbb.vowels` under the name `onze_vowels`. Our\nmodelling requires that we represent our factors as factor vectors rather\nthan character vectors. \n\n::: {.cell}\n\n```{.r .cell-code}\nonze_data <- as_tibble(onze_vowels) %>%\n  mutate(\n    across(.cols = c('speaker', 'vowel', 'word'), .fn = as.factor),\n  )\n```\n:::\n\n\n\nThe next steps will fly by without much comment. We apply Lobanov 2.0 filtering\nand remove the old F1 and F2 values for convenience.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_data <- onze_data %>%\n  lobanov_2() %>%\n  select(-(F1_50:F2_50))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(speaker, vowel)`\n```\n\n\n:::\n:::\n\nNext, we pivot the data so that the normalised F1 and F2 data appears in a \nsingle column, group the tibble and nest so that we have a row for each model\nwe want to fit.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_models <- onze_data %>%\n   pivot_longer(\n     cols = F1_lob2:F2_lob2,\n     names_to = \"formant_type\",\n     values_to = \"formant_value\"\n   ) %>%\n  group_by(vowel, formant_type) %>%\n  nest()\n```\n:::\n\n\nNow it's time to fit some models. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_models <- onze_models %>%\n  mutate(\n    model = map(\n      data,\n      ~ bam(\n        formant_value ~ gender + s(yob, by = gender) # main effects\n          + s(speech_rate) + # control variable\n          s(speaker, bs = 're') + s(word, bs = \"re\"), # random effects\n        data = .x,\n        discrete = T,\n        nthreads = 16 # I'm on a silly computer right now. \n        # Perhaps reduce nthreads to 4.\n      )\n    )\n  )\n```\n:::\n\n\n## Using `gam.check`\n\nThe function `gam.check` from `mgcv` tells us a lot about a GAMM. Here it is\nfor the first GAMM in our tibble. This can be done by taking the first object\nfrom the model column.\n\n::: {.cell}\n\n```{.r .cell-code}\ngam.check(onze_models$model[[1]])\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMethod: fREML   Optimizer: perf chol\n$grad\n[1] -2.459495e-05 -2.930034e-08 -4.469310e-05  1.003085e-05 -7.541875e-07\n[6]  1.565537e-05\n\n$hess\n           [,1]          [,2]          [,3]          [,4]          [,5]\n   2.459335e-05 -5.261901e-09 -2.823390e-11 -1.002578e-05  7.548775e-07\n  -5.261901e-09  9.229684e-02 -4.556448e-07  1.542197e-01 -6.173866e-03\n  -2.823390e-11 -4.556448e-07  4.469058e-05 -6.994732e-06 -1.076207e-06\n  -1.002578e-05  1.542197e-01 -6.994732e-06  3.353799e+01 -2.782142e-02\n   7.548775e-07 -6.173866e-03 -1.076207e-06 -2.782142e-02  1.462190e+01\nd -1.561899e-05 -3.098834e-01 -8.006339e-06 -3.960741e+01 -3.784472e+01\n           [,6]\n  -1.561899e-05\n  -3.098834e-01\n  -8.006339e-06\n  -3.960741e+01\n  -3.784472e+01\nd  3.468500e+03\n\nModel rank =  621 / 621 \n\nBasis dimension (k) checking results. Low p-value (k-index<1) may\nindicate that k is too low, especially if edf is close to k'.\n\n                   k'    edf k-index p-value  \ns(yob):genderF   9.00   1.00    1.02    0.95  \ns(yob):genderM   9.00   1.62    1.02    0.89  \ns(speech_rate)   9.00   1.00    0.97    0.02 *\ns(speaker)     100.00  79.21      NA      NA  \ns(word)        492.00  75.69      NA      NA  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\nWe get:\n\n  - A qq-plot and a histogram of residuals. Both suggest heavy tails. This \n  seems to be quite common with formant data. One option to deal with this, \n  although it increases computation load, is to use a scaled t distribution\n  as our residual model. This can be done by adding `family = scat(link='identity'))` \n  to the arguments of the `bam` function. I won't explore this option in this post.\n  - Two scatter plots of residuals. The linear predictor is the one to look at.\n  There is no obvious pattern in this case. This is good!\n  - Console output within which the main thing to check is the 'Basis dimension (k) \n  checking results'. These indicate the possible degrees of freedom (`k'`) which each\n  smooth is provided by the model specification and the effective degrees of \n  freedom (`edf`) of the smooth which has been fit to the data. We want to avoid\n  the combination of low p-values and `edf` close to `k'`. The current output\n  doesn't have anything to worry about here either. If `edf` gets close to `k'`\n  we can increase the possible 'wiggliness' of the relevant term by adding the\n  argument, say, `k = 11` (which is one higher than the default value of 10)\n  to the relevant smooth specification. When fitting the same model formula\n  to multiple datasets, we need to pick a `k` value which works for all. \n  Practically speaking, the only cost to increasing `k` is computational.\n  \n`gam.check` does not return a value. So we can't save it's results using the \n`mutate` and `map` approach used above. I suggest `walk`ing through the \ndata in the following way. This will output the plots and console output for\neach of the models in turn. The output is not given here to avoid this post \nbecoming _very_ long.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwalk2(\n  str_c(onze_models$vowel, '_', onze_models$formant_type),\n  onze_models$model,\n  ~ {\n    print(.x)\n    gam.check(.y)\n  }\n)\n```\n:::\n\n\nOne downside of the approach to fitting multiple models I'm suggesting here is\nthat the same structure has to be used for all of them. The use of `gam.check`\nhere is odd insofar as we are testing a series of particular models, but can\nonly modify the general structure which we have set to apply to each model. It\nmay be that there is a 'tidymodelling' approach which enables tweaking of each\nmodel. I'd be keen to hear of any such thing.\n\nAs always in statistics, you can't just rely on a one-size-fits-all recipe. \nReflection on the nature of your own data should always be involved in your \nselection of 'k'. \n\n## Significance Testing\n\nWe have produced models of normalised first and second formant values for New\nZealand English monophthongs over a long span of time. We've fit distinct model\nfor each vowel and formant type pair (a model for <span style=\"font-variant:\nsmall-caps;\">dress</span> F1, a model for <span style=\"font-variant:\nsmall-caps;\">dress</span> F2, &c. &c...). _Within_ each of these models, we\nfit a distinct smooth for the two gender categories in the data.\n\n### P-Values for By-Factor Smooths from the Model Summary\n\nThe simplest method, if we are interested in which trajectories through the\nvowel space represent statistically significant changes is to extract p-values\nfrom the model summaries produced by the `summary` function.\n\nIn this case, we say that a trajectory is significant if _either_ the p-value\nfor the F1 smooth _or_ the F2 smooth is less than 0.05. This kind of disjunctive\nuse of p-values leads to false positives. So, for similar reasons to those \npresented in the Sóskuthy paper linked above, it is wise to apply the Bonferroni\ncorrection here. Since two p-value are involved, we simply divide our threshold\nfor significance by 2, to give a new threshold of 0.0025.\n\nHere's what the output of `summary` applied to one of our models looks like \n(I've picked one with significant effects on year of birth).\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_index <- 3\npaste0(\"Vowel = \", onze_models$vowel[[model_index]])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Vowel = FLEECE\"\n```\n\n\n:::\n\n```{.r .cell-code}\npaste0(\"Formant type = \", onze_models$formant_type[[model_index]])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Formant type = F1_lob2\"\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(onze_models$model[[3]])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nformant_value ~ gender + s(yob, by = gender) + s(speech_rate) + \n    s(speaker, bs = \"re\") + s(word, bs = \"re\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.03870    0.02515 -41.306  < 2e-16 ***\ngenderM     -0.15620    0.02947  -5.301 1.17e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                   edf  Ref.df      F p-value    \ns(yob):genderF   1.533   1.597 65.436  <2e-16 ***\ns(yob):genderM   2.684   2.795 39.972  <2e-16 ***\ns(speech_rate)   1.000   1.000  1.924   0.165    \ns(speaker)      74.509  96.000  7.205  <2e-16 ***\ns(word)        215.748 734.000  1.968  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.221   Deviance explained =   24%\nfREML =  10133  Scale est. = 0.30672   n = 11896\n```\n\n\n:::\n:::\n\nThis is the model for <span style=\"font-variant: small-caps;\">fleece</span> F1.\nThe parametric coefficients show the intercept terms for the women (`(Intercept)`)\nand the `genderM` term for the men. This gives the average (normalised) value for\n<span style=\"font-variant: small-caps;\">fleece</span> F1 for the women and the\n_difference_ between this and the average for the men. The difference between\nthese values comes out as significant. But what we're really interested in is\nwhether they differ across the year of birth variable. \n\nTo see this, we look at the smooth terms. As the heading suggests, these are \n'approximate' significances. For our purposes, this just means there's\n'mathematical dragons lurking about here. All we ought to know is that, if a \np-value is 'quite close' to our cut off, we should report that. The p-values\nwe are looking at for this model do not have this problem. We're looking at\nthe values for `s(yob):genderF` and `s(yob):genderM`. In both cases, they are \nless than $2\\times10^{-16}$.\n\nWhile we're at it, let's plot these smooths using the `plot_smooth` function\nfrom `itsadug`.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_smooth(\n  onze_models$model[[model_index]], \n  view=\"yob\", \n  plot_all = \"gender\",\n  main = \"FLEECE F1 Year of Birth Smooths\",\n  rug = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSummary:\n\t* gender : factor; set to the value(s): F, M. \n\t* yob : numeric predictor; with 30 values ranging from 1864.000000 to 1981.000000. \n\t* speech_rate : numeric predictor; set to the value(s): 4.5576. \n\t* speaker : factor; set to the value(s): IA_f_527. (Might be canceled as random effect, check below.) \n\t* word : factor; set to the value(s): word_12921. (Might be canceled as random effect, check below.) \n\t* NOTE : The following random effects columns are canceled: s(speaker),s(word)\n \n```\n\n\n:::\n\n::: {.cell-output-display}\n![Smooths for males and females from FLEECE F1 model.](index_files/figure-html/fleece-smooths-1.png){width=672}\n:::\n:::\n\n\nThere's no way to tell from the `summary` output what the nature of the two \nsmooths is. We will turn to the question of whether the two smooths are significantly\ndifferent _from one another_ in moment. But with the current model, we can see\nthat both a significantly different _from 0_. \n\nIn order for us to access the p-values for `s(yob):genderM` and `s(yob):GenderF`\nfor _all_ of our models at once, we need to know a bit more about how the output\nof `summary` is stored by R: `summary`, when applied to a GAMM, produces a named\nlist with information about the GAMM (run `?summary.gam` to see the details). \nWe need the first two smooth p-values. These are stored with the name `s.pv`.\n\nTo extract this information for each model, we create a new column which\nextracts the p-values for the smooths from the summary of each GAMM, and then\ncolumns for each of the p-values we are interested in. This can be done as\nfollows:\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_models <- onze_models %>%\n  mutate(\n    model_smooth_pvs = map(\n      model,\n      ~ summary(.x)$s.pv\n    ),\n    genderF_smooth_pv = map_dbl(\n      model_smooth_pvs,\n      ~ .x[[1]]\n    ),\n    genderM_smooth_pv = map_dbl(\n      model_smooth_pvs,\n      ~ .x[[2]]\n    )\n  ) %>%\n  select(-model_smooth_pvs)\n```\n:::\n\nNotice the use of `map_dbl`, which ensures that the resulting column is\nnumerical rather than a list column. If anyone reading this has any idea of how\nto generate approximate p-values for the smooth terms in these models without\nrunning `summary`, I'd greatly appreciate it! This block takes a very long time\nto run.\n\nWe can look at the trajectories which appear as significant for either the males\nor females using the following code:\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_models %>%\n  select(-model, -data) %>% # Sometimes it's good to exclude the columns with \n  # large objects. \n  filter(genderF_smooth_pv < 0.05 | genderM_smooth_pv < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 4\n# Groups:   vowel, formant_type [20]\n   vowel   formant_type genderF_smooth_pv genderM_smooth_pv\n   <fct>   <chr>                    <dbl>             <dbl>\n 1 THOUGHT F1_lob2             0.237            0.00000107 \n 2 THOUGHT F2_lob2             0.0646           0.00454    \n 3 FLEECE  F1_lob2             0                0          \n 4 FLEECE  F2_lob2             0.00143          0          \n 5 KIT     F1_lob2             0                0          \n 6 KIT     F2_lob2             0                0          \n 7 DRESS   F1_lob2             0                0          \n 8 DRESS   F2_lob2             0.0454           0.000601   \n 9 GOOSE   F1_lob2             0                0.00000863 \n10 GOOSE   F2_lob2             0.000124         0          \n11 TRAP    F1_lob2             0                0          \n12 TRAP    F2_lob2             0.000969         0.254      \n13 START   F1_lob2             0.00438          0.000000694\n14 START   F2_lob2             0.0269           0.0154     \n15 STRUT   F1_lob2             0.0000647        0          \n16 STRUT   F2_lob2             0                0.000000718\n17 NURSE   F1_lob2             0                0          \n18 NURSE   F2_lob2             0.00000633       0.00000139 \n19 LOT     F1_lob2             0.00136          0.428      \n20 LOT     F2_lob2             0.00000706       0          \n```\n\n\n:::\n:::\n\nEach is 'significant' by the 0.05 threshold for one gender or the other.\n\n### Plotting Significance of By-Factor Smooths in Vowel Space\n\nHere, I again copy the steps in the previous post. The only difference here is \nthat we are going to have information about significance along with our \npredicted formant values.\n\nWe generate model predictions from each model:\n\n::: {.cell}\n\n```{.r .cell-code}\nto_predict <- list(\n  \"yob\" = seq(from=1864, to=1981, by=1), # All years\n  \"gender\" = c(\"M\", \"F\")\n) \n# BTW: Get prediction will just assume the average value for any predictors not\n# mentioned (in this case, Speech_rate).\n\nonze_models <- onze_models %>%\n  mutate(\n    prediction = map(\n      model, # This time we're applying the function to all the models.\n      # We again introduce the function with '~', and indicate where the model \n      # goes with '.x'.\n      ~ get_predictions(model = .x, cond = to_predict, print.summary = FALSE)\n    )\n  )\n```\n:::\n\n\nWe then unnest the predictions, making sure to keep our p-value information.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_predictions <- onze_models %>%\n  select(\n    vowel, formant_type, genderF_smooth_pv, genderM_smooth_pv, prediction\n  ) %>%\n  unnest(prediction)\n```\n:::\n\n\nWe still need to pivot our data so that we have distinct columns for the fit and\nthe p-value for each formant type.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_predictions <- onze_predictions %>%\n  mutate(\n    p_value = if_else(gender == \"F\", genderF_smooth_pv, genderM_smooth_pv)\n  ) %>%\n  select( # Remove unneeded variables\n    -speech_rate,\n    -CI,\n    -genderF_smooth_pv,\n    -genderM_smooth_pv\n  ) %>%\n  pivot_wider( # Pivot\n    names_from = formant_type,\n    values_from = c(fit, p_value)\n  )\n```\n:::\n\n\nOur significance test for each vowel is to test whether either of the p-values\nfor the vowel is less than 0.025. We make a new column to track this.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_predictions <- onze_predictions %>%\n  mutate(\n    is_sig = (p_value_F1_lob2 < 0.025 | p_value_F2_lob2 < 0.025),\n  )\n```\n:::\n\n\nLet's have a look at which of these turn up as significant:\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_predictions %>%\n  group_by(vowel, gender) %>%\n  summarise(is_sig = first(is_sig)) %>%\n  arrange(is_sig)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'vowel'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n# Groups:   vowel [10]\n   vowel   gender is_sig\n   <fct>   <fct>  <lgl> \n 1 THOUGHT F      FALSE \n 2 DRESS   M      TRUE  \n 3 DRESS   F      TRUE  \n 4 FLEECE  M      TRUE  \n 5 FLEECE  F      TRUE  \n 6 GOOSE   M      TRUE  \n 7 GOOSE   F      TRUE  \n 8 KIT     M      TRUE  \n 9 KIT     F      TRUE  \n10 LOT     M      TRUE  \n11 LOT     F      TRUE  \n12 NURSE   M      TRUE  \n13 NURSE   F      TRUE  \n14 START   M      TRUE  \n15 START   F      TRUE  \n16 STRUT   M      TRUE  \n17 STRUT   F      TRUE  \n18 THOUGHT M      TRUE  \n19 TRAP    M      TRUE  \n20 TRAP    F      TRUE  \n```\n\n\n:::\n:::\n\nOf our 10 vowels, the only one which does not come up as significant is \n<span style=\"font-variant: small-caps;\">thought</span>\nfor the female speakers.\n\nWe will visualise significance in two ways. The first is to decrease the\ntransparency of any vowel which does not meet our significance threshold, the \nsecond is to add to our vowel labels and indication of the p-values for \nF1 and F2 for each vowel. We'll do this by adding a tag of the form '(** | *)'\nwhere the first set of stars indicates the magnitude of the F1 p-value and the\nsecond indicates the magnitude of the F2 p-value. We'll use the usual stars \nfor p-values. These can be conveniently generated using the `stars.pval` function\nfrom the `gtools` package.\n\nWe create the labels as follows:\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_predictions <- onze_predictions %>%\n  mutate(\n    F1_stars = stars.pval(p_value_F1_lob2),\n    F2_stars = stars.pval(p_value_F2_lob2),\n    vowel_label = glue(\n      \"{vowel}\\n({F1_stars}|{F2_stars})\"\n    )\n  )\n```\n:::\n\n\nNow we apply the static plot code from the previous post.\n\n::: {.cell}\n\n```{.r .cell-code}\nfirst_obs <- onze_predictions %>%\n  group_by(vowel, gender) %>%\n  slice(which.min(yob))\n\nstatic_plot <- onze_predictions %>%\n  ggplot(\n    aes(\n      x = fit_F2_lob2,\n      y = fit_F1_lob2,\n      colour = vowel,\n      label = vowel_label,\n      alpha = is_sig\n    )\n  ) +\n  geom_path(\n    arrow = arrow(length = unit(2.5, \"mm\")), # Make arrows smaller\n    show.legend = FALSE\n  ) +\n  geom_label(\n    data = first_obs, \n    show.legend = FALSE,\n    size = 2, # Make labels small,\n    alpha = 0.7\n  ) +\n  scale_x_reverse(expand = expansion(add = 0.7)) + # less expanasion needed.\n  scale_y_reverse() +\n  scale_alpha_manual(values = c('FALSE' = 0.2, 'TRUE' = 1)) +\n  facet_grid(\n    cols = vars(gender)\n  ) +\n  labs(\n    title = \"Vowel Space Change in NZE (yob: 1864-1981)\",\n    x = \"Second Formant (Lobanov 2.0)\",\n    y = \"First Formant (Lobanov 2.0)\"\n  )\n\nstatic_plot\n```\n\n::: {.cell-output-display}\n![ONZE by-gender smooths, with significance indicated.](index_files/figure-html/onze-sig-plot-1.png){width=672}\n:::\n:::\n\n\nThe plot here creates somewhat unwieldy labels. The advantage of these is that\nthey give us a bit more detail than merely 'is significant' or 'is not significant'.\nThis is particularly important given that these plots will typically be used\nin exploratory rather than confirmatory contexts. It is _also_ important that\nwe provide some indication of the specific p-values. Those which are near 0.05\nshould be treated with a bit of scepticism.\n\nAnd now, the same plot but animated:\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_anim <- onze_predictions %>%\n  ggplot(\n    aes(\n      x = fit_F2_lob2,\n      y = fit_F1_lob2,\n      colour = vowel,\n      label = vowel_label,\n      alpha = is_sig\n    )\n  ) +\n  geom_path(show.legend = FALSE) +\n  # NB: our labels just use the predictions dataframe now, so no need for the\n  # 'data = ' line.\n  geom_label( \n    show.legend = FALSE,\n    size = 2.5\n  ) +\n  scale_x_reverse(expand = expansion(add = 0.5)) + \n  scale_y_reverse() +\n  facet_grid(\n    cols = vars(gender)\n  ) +\n  labs(\n    title = \"Vowel Space Change in NZE (yob: 1864-1981)\",\n    x = \"Second Formant (Lobanov 2.0)\",\n    y = \"First Formant (Lobanov 2.0)\",\n    caption = 'Year of Birth: {round(frame_along, 0)}' \n  ) +\n  theme(\n    plot.caption = element_text(size = 14, hjust = 0)\n  ) +\n  transition_reveal(along = yob)\n\nanimate(onze_anim, end_pause = 10)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using alpha for a discrete variable is not advised.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.gif)\n:::\n:::\n\nHere the transparent applies to both the labels _and_ the paths.\n\nYou might think that we should be applying some kind of multiple comparisons\ncorrection for the fact we are looking at 20 distinct statistical models! That\nwould be the case if we were testing the hypothesis that there is some\nsignificant effect in _one_ of the vowels we are looking at. I'd suggest that\nthat is not an interesting hypothesis! What we're trying to get at with these\ntools is a sense of systematic change in the data. If we wanted to turn this \ninto a severe hypothesis test, we would need a much more worked out hypothesis \nwhich covered both _which_ vowels we expect to have significant effects in the\nvowel space and _what_ we expect those effects to be.\n\n### P-Values for Difference Smooths\n\nIf we want to know whether differences between the trajectories are significant,\nthen we need a different model structure. Rather than fitting distinct smooths\nto the two levels of our gender variable, we need to fit a smooth for the female\nspeakers and a _difference_ smooth for the males. This smooth represents, as the\nname suggests, the difference between the shapes of the smooths for the male and\nfemale speakers.\n\nThe difference smooth structure is implemented by `mgcv` when we use ordered\nfactors with contrast-treatment coding. This is done in R as follows:\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_data <- onze_data %>%\n  mutate(\n    gender = as.ordered(gender)\n  )\n\ncontrasts(onze_data$gender) <- 'contr.treatment'\n```\n:::\n\n\nWe also have to change the model structure slightly. \nThe difference between the needed model structure the structure used for\nby-factor smooths is that with difference smooths on a variable $x$ by some\nfactor $y$, the model formula looks like `y + s(x) + s(x, by=y)` whereas if a\nsmooth is fit to each level of the factor $y$ independently the formula looks \nlike `y + s(x, by=y)`. \nThe former structure is not actually [identifiable](https://en.wikipedia.org/wiki/Identifiability) if you\ndo not have contrast coded ordered factors. It's important to be clear whether\nyou are fitting by-factor level smooths or difference smooths!\n\nWe fit new models. Here, to avoid the models dataframe exploding, I'll just\nreplace the old ones. In a real research project, you will probably want to \nsave the original models before you do this.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_models <- onze_data %>%\n  # Rerun the nesting steps.\n  pivot_longer(\n     cols = F1_lob2:F2_lob2,\n     names_to = \"formant_type\",\n     values_to = \"formant_value\"\n   ) %>%\n  group_by(vowel, formant_type) %>%\n  nest() %>%\n  # Rerun modelling with new structure\n  mutate(\n    model = map(\n      data,\n      ~ bam(\n        formant_value ~ gender + s(yob) + s(yob, by = gender) # main effects\n          + s(speech_rate) + # control variable\n          s(speaker, bs = 're') + s(word, bs = \"re\"), # random effects\n        data = .x,\n        discrete = T,\n        nthreads = 16 \n      )\n    )\n  )\n```\n:::\n\n\nWe skip checking the model assumptions here. The same points as above apply.\n\nLet's have a look at a model summary for the same example as before (<span\nstyle=\"font-variant: small-caps;\">fleece</span>) F1). \n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(onze_models$model[[model_index]])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nformant_value ~ gender + s(yob) + s(yob, by = gender) + s(speech_rate) + \n    s(speaker, bs = \"re\") + s(word, bs = \"re\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.03295    0.02509  -41.17  < 2e-16 ***\ngenderM     -0.15884    0.02947   -5.39 7.19e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                   edf  Ref.df      F p-value    \ns(yob)           2.093   2.180 45.640  <2e-16 ***\ns(yob):genderM   2.072   2.161  1.415   0.274    \ns(speech_rate)   1.000   1.000  2.034   0.154    \ns(speaker)      74.459  96.000  7.253  <2e-16 ***\ns(word)        215.736 734.000  1.969  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.221   Deviance explained =   24%\nfREML =  10133  Scale est. = 0.30672   n = 11896\n```\n\n\n:::\n:::\n\nThe story we tell here is a bit different than the one we offered above. We have\nto account for both the parametric terms and the smooth terms. In the parametric\ncoefficients, we see that the female speakers have an average F1 of -1.03295 in\nour Lobanov 2.0 normalised values. The `genderM` coefficient tells us that the\nmale speakers have a value of which is smaller than the female speakers by \n0.15884. That is, the male average is -1.19179. That is,\nin terms of the vowel space, their average \n<span style=\"font-variant: small-caps;\">fleece</span> vowel is higher.\n\nThe smooth terms then tell us about the shape of the change in male and female\nspeakers over time. We see that `s(yob)`, the smooth for female speakers, is\n'statistically significant'. That is, there is change over time in this variable\nfor our female speakers. The coefficient `s(yob):genderM` now indicates the \ndifference in shape of the change over time between our female and male speakers.\nIt is _not_ statistically significant in this case. That is, the _shape_ of the\nchange over time could be the same for both speakers. This is quite different\nfrom the interpretation of `s(yob):genderM` in our previous model structure.\n\nThis case is interesting in that it looks intuitively from the animation in the\nprevious section, that female speakers are leading the change in the height\nof <span style=\"font-variant: small-caps;\">fleece</span>, with the male speakers\nfollowing after a delay. The model, however, is representing this as males being\nacross-the-board higher in their <span style=\"font-variant: small-caps;\">fleece</span>\nvowel, while potentially following the same shape as the female speakers.\n\nWhen thinking about change over time in the vowel space, we might be interested\nin differences in _shape_ between men and women but not in across-the-board\ndifferences in height. With that in mind, we can plot those trajectories which\nhave significant differences in shape across male and female speakers.\n\nFollowing the same pattern as above, we say that a vowel has a significant \ndifference in shape between male and female speakers if one or the other formant\nvalues has an `s(yob):genderM` p-value less than 0.0025. We follow the previous\nsteps without much comment:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_models <- onze_models %>%\n  mutate(\n    diff_smooth_pv = map_dbl(\n      model,\n      ~ summary(.x)$s.pv[[2]]\n    )\n  )\n\nonze_models <- onze_models %>%\n  mutate(\n    prediction = map(\n      model, \n      ~ get_predictions(model = .x, cond = to_predict, print.summary = FALSE)\n    )\n  )\n\nonze_predictions <- onze_models %>%\n  select(\n    vowel, formant_type, diff_smooth_pv, prediction\n  ) %>%\n  unnest(prediction)\n\nonze_predictions <- onze_predictions %>%\n  select( # Remove unneeded variables\n    -speech_rate,\n    -CI\n  ) %>%\n  pivot_wider( # Pivot\n    names_from = formant_type,\n    values_from = c(fit, diff_smooth_pv)\n  )\n\nonze_predictions <- onze_predictions %>%\n  mutate(\n    is_sig = (diff_smooth_pv_F1_lob2 < 0.025 | diff_smooth_pv_F2_lob2 < 0.025),\n  )\n```\n:::\n\n\nWe now create labels and produce the static plot. Code which is changed from\nabove is indicated in comments.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_predictions <- onze_predictions %>%\n  mutate(\n    F1_stars = stars.pval(diff_smooth_pv_F1_lob2),\n    F2_stars = stars.pval(diff_smooth_pv_F2_lob2),\n    vowel_label = glue(\n      \"{vowel}\\n({F1_stars}|{F2_stars})\"\n    )\n  )\n\nfirst_obs <- onze_predictions %>%\n  group_by(vowel, gender) %>%\n  slice(which.min(yob))\n\nstatic_plot <- onze_predictions %>%\n  ggplot(\n    aes(\n      x = fit_F2_lob2,\n      y = fit_F1_lob2,\n      colour = vowel,\n      label = vowel_label,\n      alpha = is_sig\n    )\n  ) +\n  geom_path(\n    arrow = arrow(length = unit(2.5, \"mm\")), # Make arrows smaller\n    show.legend = FALSE\n  ) +\n  geom_label(\n    data = first_obs, \n    show.legend = FALSE,\n    size = 2, # Make labels small\n    ### NB: alpha removed from here - labels will change transparency as well\n    ## as paths.\n  ) +\n  scale_x_reverse(expand = expansion(add = 0.7)) + # less expanasion needed.\n  scale_y_reverse() +\n  scale_alpha_manual(values = c('FALSE' = 0.2, 'TRUE' = 1)) +\n  facet_grid(\n    cols = vars(gender)\n  ) +\n  labs(\n    title = \"Vowel Space Change in NZE (yob: 1864-1981)\",\n    subtitle = \"Significant Shape Difference Between Genders\",\n    x = \"Second Formant (Lobanov 2.0)\",\n    y = \"First Formant (Lobanov 2.0)\"\n  )\n\nstatic_plot\n```\n\n::: {.cell-output-display}\n![ONZE smooths, with significant gender differences indicated.](index_files/figure-html/onze-diff-plot-1.png){width=672}\n:::\n:::\n\nFigure \\ref(fig:onze-diff-plot) suggests that there are significant differences\nin the shape of change between the male and female speakers\nfor <span style=\"font-variant: small-caps;\">nurse</span>, <span style=\"font-variant: small-caps;\">goose</span>,\nabd <span style=\"font-variant: small-caps;\">thought</span>.\n\nThis can be converted into an animated plot using the same approach as for the\nanimated plot in the previous section.\n\n### Pointwise Significance of Difference Smooths\n\nThe p-values in the summaries of difference smooth models provide a sense of \nwhether the appropriate smooth for two levels of a factor differ in\nshape and _overall_.\nWe might, instead, be interested in a pointwise, or even range-wise, sense of\nsignificance. In this case, we might ask if the smooths for men and women are\nsignificantly different for speakers born between 1860-1880 or between 1900-1920\netc. This is closely related to the visual method of significance testing which\nSóskuthy expresses some caution about. \n\nThe method is simply to look at the plot of the smooths for each factor level\nin a difference smooth model and, if there is a point where their confidence\nintervals separate, to declare the difference significant. Sóskuthy advises that\nwe only do this if we have a concrete hypothesis about the range in which the\nsmooths will differ. If not, we open the door to an unacceptable number of \nfalse positives. (A second version of this approach looks at a plot of the\ndifference between the two and looks for ranges in which 0 is not included \nwithin the confidence interval).\n\nThis caution is certainly important in a confirmatory setting. Here, in an\nexploratory setting, we can just be aware that we shouldn't expend energy trying\nto interpret pointwise differences between two smooths. This is easy enough to\navoid if we keep in mind our actual subject matter! If there are two years in\nour data in which men and women has a 'significant' difference between their\nsmooths, say 1872 and 1873, we are not going to rush to the journals with a\npaper on the sociolinguistics of gender difference in 1872 and 1873. We just\ndon't expect that kind of resolution from this data and these methods of\nanalysis.\n\nOne final note about this method is that it includes both the shape _and_ the\nintercept terms. Two smooths which are identical in shape but are vertical \ntranslations of one another and do not have overlapping confidence intervals \nwill appear as significantly different across their whole range.\n\nThe aim in this (final!) section will be to show how to extract 'significantly\ndifferent' ranges from our smooths and to plot them in the vowel space. The core\nidea is to use the `get_difference` function from the `itsadug` package, which\nreturns the difference smooth and its confidence intervals.\n\nLet's look at this function for the <span style=\"font-variant: small-caps;\">fleece</span>\nF1 model. First, it will be useful to see the difference smooth itself.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_diff(\n  onze_models$model[[model_index]],\n  view = \"yob\",\n  comp = list(\"gender\" = c(\"F\", \"M\"))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSummary:\n\t* yob : numeric predictor; with 100 values ranging from 1864.000000 to 1981.000000. \n\t* speech_rate : numeric predictor; set to the value(s): 4.5576. \n\t* speaker : factor; set to the value(s): IA_f_527. (Might be canceled as random effect, check below.) \n\t* word : factor; set to the value(s): word_12921. (Might be canceled as random effect, check below.) \n\t* NOTE : The following random effects columns are canceled: s(speaker),s(word)\n \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nyob window(s) of significant difference(s):\n\t1877.000000 - 1981.000000\n```\n\n\n:::\n:::\n\nThe above plot shows the difference between female and male speakers in their \nsmooths for <span style=\"font-variant: small-caps;\">fleece</span> F1. The \nred line indicates the range of years of birth for which the two are taken to \nbe significantly different.\n\nThe `get_difference` function helps us to find these ranges directly. \nFor instance:\n\n::: {.cell}\n\n```{.r .cell-code}\nto_predict <- list(\n  \"yob\" = seq(from=1864, to=1981, by=1) # All years\n) \n\nfleece_difference_smooth <- get_difference(\n  onze_models$model[[model_index]],\n  cond = to_predict,\n  comp = list(\"gender\" = c(\"F\", \"M\"))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSummary:\n\t* yob : numeric predictor; with 118 values ranging from 1864.000000 to 1981.000000. \n\t* speech_rate : numeric predictor; set to the value(s): 4.5576. \n\t* speaker : factor; set to the value(s): IA_f_527. (Might be canceled as random effect, check below.) \n\t* word : factor; set to the value(s): word_12921. (Might be canceled as random effect, check below.) \n\t* NOTE : The following random effects columns are canceled: s(speaker),s(word)\n \n```\n\n\n:::\n\n```{.r .cell-code}\nfleece_difference_smooth %>%\n  mutate(\n    # If the estimate for the difference smooth minus the confidence interval\n    # value is greater than 0 or the difference smooth plus the confidence\n    # interval value is less than 0, then the confidence band does not include\n    # 0. In this case, the difference at that point is 'significant'.\n    sig_diff = (difference - CI) > 0 | (difference + CI) < 0\n  ) %>%\n  head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    yob speech_rate  speaker       word difference        CI sig_diff\n1  1864      4.5576 IA_f_527 word_12921 0.05790359 0.1414914    FALSE\n2  1865      4.5576 IA_f_527 word_12921 0.06196859 0.1375988    FALSE\n3  1866      4.5576 IA_f_527 word_12921 0.06603054 0.1338369    FALSE\n4  1867      4.5576 IA_f_527 word_12921 0.07008477 0.1302179    FALSE\n5  1868      4.5576 IA_f_527 word_12921 0.07412524 0.1267523    FALSE\n6  1869      4.5576 IA_f_527 word_12921 0.07814509 0.1234480    FALSE\n7  1870      4.5576 IA_f_527 word_12921 0.08213722 0.1203095    FALSE\n8  1871      4.5576 IA_f_527 word_12921 0.08609447 0.1173372    FALSE\n9  1872      4.5576 IA_f_527 word_12921 0.09000985 0.1145281    FALSE\n10 1873      4.5576 IA_f_527 word_12921 0.09387715 0.1118768    FALSE\n11 1874      4.5576 IA_f_527 word_12921 0.09769055 0.1093757    FALSE\n12 1875      4.5576 IA_f_527 word_12921 0.10144559 0.1070174    FALSE\n13 1876      4.5576 IA_f_527 word_12921 0.10513947 0.1047953     TRUE\n14 1877      4.5576 IA_f_527 word_12921 0.10877103 0.1027050     TRUE\n15 1878      4.5576 IA_f_527 word_12921 0.11234046 0.1007440     TRUE\n```\n\n\n:::\n:::\n\nThe above output gives the first 15 rows, and shows that the significant\ndifference between smooths starts in 1876.\n\nTo apply the function to all models we use the following code:\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_models <- onze_models %>%\n  mutate(\n    sig_diffs = map(\n      model,\n      ~ get_difference(\n          .x,\n          cond = to_predict,\n          comp = list(\"gender\" = c(\"F\", \"M\")),\n          print.summary = FALSE\n        ) %>%\n        mutate(\n          sig_diff = (difference - CI) > 0 | (difference + CI) < 0\n        ) %>%\n        select(yob, sig_diff)\n    )\n  )\n```\n:::\n\n\nWe want to take the years and whether the difference is significant for each\nmodel. We do this by unnesting in much the same way that we generated\n`onze_predictions`.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_sig_diffs <- onze_models %>%\n  select(\n    vowel, formant_type, sig_diffs\n  ) %>%\n  unnest(sig_diffs)\n```\n:::\n\n\nWe then need to aggregate these ranges so that a difference appears as\nsignificant in the vowel space plot if either the F1 or the F2 smooths are\nsignificantly different across genders.\n\nThis is done as follows: \n\n::: {.cell}\n\n```{.r .cell-code}\nonze_sig_diffs <- onze_sig_diffs %>%\n  pivot_wider(\n    names_from = formant_type,\n    values_from = sig_diff\n  ) %>%\n  mutate(\n    sig_diff = F1_lob2 | F2_lob2\n  ) %>%\n  select(\n    -(F1_lob2:F2_lob2)\n  )\n```\n:::\n\n\nSince we already have predictions from these models from the previous section,\nI'll add this information about significant ranges by using `left_join`.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_predictions <- onze_predictions %>%\n  left_join(\n    onze_sig_diffs\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(vowel, yob)`\n```\n\n\n:::\n:::\n\n\nFinally, we plot. In this case, we'll go straight to the animated plot. The\nbasic idea will be to have low transparency when differences significant and\nhigh transparency when they are not.\n\n::: {.cell}\n\n```{.r .cell-code}\nonze_diff_anim <- onze_predictions %>%\n  ggplot(\n    aes(\n      x = fit_F2_lob2,\n      y = fit_F1_lob2,\n      colour = vowel,\n      fill = sig_diff,\n      label = vowel,\n      group = vowel,\n      alpha = sig_diff\n    )\n  ) +\n  geom_path(show.legend = FALSE) +\n  # NB: our labels just use the predictions dataframe now, so no need for the\n  # 'data = ' line.\n  geom_label(\n    show.legend = FALSE,\n    size = 2.5\n  ) +\n  scale_x_reverse(expand = expansion(add = 0.5)) + \n  scale_y_reverse() +\n  scale_alpha_manual(values = c('FALSE' = 0.2, 'TRUE' = 0.9)) +\n  scale_fill_manual(values = c(\"FALSE\" = \"grey\", \"TRUE\" = \"white\")) +\n  facet_grid(\n    cols = vars(gender)\n  ) +\n  labs(\n    title = \"Vowel Space Change in NZE (yob: 1864-1981)\",\n    subtitle = \"Significant Differences Between Gender Smooths\",\n    x = \"Second Formant (Lobanov 2.0)\",\n    y = \"First Formant (Lobanov 2.0)\",\n    caption = 'Year of Birth: {round(frame_along, 0)}\\n Grey indicates non-significant differences between male and\\n female smooths.' \n  ) +\n  theme(\n    plot.caption = element_text(size = 14, hjust = 0)\n  ) +\n  transition_reveal(along = yob)\n\nanimate(onze_diff_anim, end_pause = 10)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.gif)\n:::\n:::\n\nIt remains to be seen how useful this kind of plot is for interpreting vowel\nspace change. In this case, for many vowels we seem to start with insignificant\ndifference, enter a long period of change, and, for many vowels, end up with\ninsignificant differences. This would have to be distinguished from the fact\nthat confidence intervals tend to flare out at the extremes of smooths.\n\n## Conclusion\n\nThis post has expanded on my previous post on fitting independent models to the\nF1 and F2 data of multiple vowels using the nest and mutate approach of the\n`purrr` package. I've covered something of how to check the health of each of\nthe models and how to extract information about whether the difference between\ntwo smooths is significant using some of the methods mentioned in [Sóskuthy (2021)](https://www.sciencedirect.com/science/article/pii/S009544702030108X). \nIn particular, we have followed his advice about the use of _difference smooths_\nand the use of the Bonferroni correction.\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}